{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# BASELINE MODEL NOTEBOOK\n",
    "Felix A. Westphal\n",
    "DLMDWME01\n",
    "\n",
    "### Import"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-05-21T12:15:59.052992Z",
     "end_time": "2023-05-21T12:15:59.140900Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Parameter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "outputs": [],
   "source": [
    "FILE_PATH_BALANCED_DATA = r\"../data/processed/Balanced_Input_Data.csv\"\n",
    "FILE_PATH_NORMALIZED_DATA = r\"../data/processed/Normalized_Input_Data.csv\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-21T12:15:59.064525Z",
     "end_time": "2023-05-21T12:15:59.186851Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from Excel: \n",
      "                 tmsp    amount  success  3D_secured  Austria  Germany  \\\n",
      "0 2019-01-01 00:01:11  0.133013    False       False    False     True   \n",
      "1 2019-01-01 00:01:17  0.133013     True       False    False     True   \n",
      "2 2019-01-01 00:02:49  0.371795    False        True    False     True   \n",
      "3 2019-01-01 00:03:13  0.371795     True        True    False     True   \n",
      "4 2019-01-01 00:04:33  0.189103    False       False     True    False   \n",
      "\n",
      "   Switzerland  Goldcard  Moneycard  Simplecard  UK_Card  Diners  Master  \\\n",
      "0        False     False      False       False     True   False   False   \n",
      "1        False     False      False       False     True   False   False   \n",
      "2        False     False      False       False     True    True   False   \n",
      "3        False     False      False       False     True    True   False   \n",
      "4        False     False      False        True    False    True   False   \n",
      "\n",
      "    Visa  num_tries  order_id      hour  is_weekend  \n",
      "0   True          1         1  0.133013       False  \n",
      "1   True          2         1  0.133013       False  \n",
      "2  False          1         2  0.371795       False  \n",
      "3  False          1         3  0.371795       False  \n",
      "4  False          1         4  0.189103       False  \n"
     ]
    }
   ],
   "source": [
    "input_data = pd.read_csv(FILE_PATH_NORMALIZED_DATA, parse_dates=[0])                        # Load input data file\n",
    "print(f\"Data loaded from Excel: \\n{input_data.head()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-21T12:15:59.080823Z",
     "end_time": "2023-05-21T12:15:59.249821Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train and Test Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset: \n",
      "           hour    amount  3D_secured  is_weekend  Goldcard  Simplecard  \\\n",
      "42485  0.182692  0.182692       False       False     False        True   \n",
      "18229  0.126603  0.126603        True       False     False       False   \n",
      "14138  0.333333  0.333333        True       False     False       False   \n",
      "47317  0.198718  0.198718        True       False     False        True   \n",
      "35141  0.139423  0.139423        True        True     False       False   \n",
      "\n",
      "       UK_Card  \n",
      "42485    False  \n",
      "18229     True  \n",
      "14138     True  \n",
      "47317    False  \n",
      "35141     True  \n",
      "Number of failed transactions: 24073\n",
      "Number of succeeded transactions: 6223\n"
     ]
    }
   ],
   "source": [
    "input_data = input_data[input_data['num_tries'] == 1]                                                   # Only consider first tries\n",
    "\n",
    "X = input_data[['hour', 'amount', '3D_secured', 'is_weekend', 'Goldcard', 'Simplecard', 'UK_Card']]     # Selected Features\n",
    "y = input_data['success']                                                                               # Target Variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "#training,test = train_test_split(model_data, train_size = 0.7, test_size = 0.3, shuffle=True)          # Performance Verschlechterung: 79% (Train and Testset Settings)\n",
    "#training, valid = train_test_split(training, train_size = 0.7, test_size =0.3, shuffle=True)\n",
    "print(f\"Train Dataset: \\n{X_train.head()}\")\n",
    "\n",
    "# --- Check Dataset Distribution\n",
    "failed_transaction = y_train[y_train == False]\n",
    "succeeded_transaction = y_train[y_train == True]\n",
    "num_failed = len(failed_transaction.index)\n",
    "num_succeeded = len(succeeded_transaction.index)\n",
    "print(\"Number of failed transactions: \" + str(num_failed))\n",
    "print(\"Number of succeeded transactions: \" + str(num_succeeded))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-21T12:15:59.226821Z",
     "end_time": "2023-05-21T12:15:59.260821Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Baseline Model - Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28635276 0.23962683 0.24375885 ... 0.20554243 0.12375475 0.14714824]\n"
     ]
    }
   ],
   "source": [
    "logReg_model = LogisticRegression(max_iter=200, random_state=0, solver='lbfgs', multi_class='multinomial')                     # Create a Logistic Regression model\n",
    "logReg_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_logReg = logReg_model.predict(X_test)            # Make predictions on the test set\n",
    "proba_pred_logReg = logReg_model.predict_proba(X_test)  # Predict probabilities for the test data\n",
    "\n",
    "# --- Extract the probabilities for the positive class (success)\n",
    "success_prob_logReg = proba_pred_logReg[:, 1]\n",
    "print(success_prob_logReg)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-21T12:15:59.255822Z",
     "end_time": "2023-05-21T12:15:59.377821Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Baseline Model - Decision Tree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "outputs": [],
   "source": [
    "decTree_model = DecisionTreeClassifier(max_depth=4, criterion='entropy')    # Create a Decision Tree classifier\n",
    "decTree_model.fit(X_train, y_train)\n",
    "y_pred_decTree = decTree_model.predict(X_test)                              # Make predictions on the test set"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-21T12:15:59.379822Z",
     "end_time": "2023-05-21T12:15:59.424837Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Baseline Model - Random Forest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "outputs": [],
   "source": [
    "ranForest_model = RandomForestClassifier(max_depth=4)       # Create a Random Forest classifier\n",
    "ranForest_model.fit(X_train, y_train)\n",
    "y_pred_ranForest = ranForest_model.predict(X_test)          # Make predictions on the test set"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-21T12:15:59.426839Z",
     "end_time": "2023-05-21T12:15:59.964920Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Baseline Model - XGBoost"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.01],\n",
    "    'max_depth': [3, 6],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'n_estimators': [100, 1000]\n",
    "}\n",
    "\n",
    "xgBoost_model = XGBClassifier(\n",
    "    colsample_bytree=0.8,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    n_estimators=1000,\n",
    "    subsample=0.8\n",
    ")\n",
    "\n",
    "# --- Perform grid search cross-validation\n",
    "#grid_search = GridSearchCV(estimator=xgBoost_model, param_grid=param_grid, cv=3, scoring='accuracy')\n",
    "#grid_search.fit(X_train, y_train)\n",
    "\n",
    "# --- Get the best hyperparameters and the corresponding model\n",
    "#best_params = grid_search.best_params_\n",
    "#best_model = grid_search.best_estimator_\n",
    "\n",
    "#best_model = grid_search.best_estimator_\n",
    "#print(f\"Best Hyperparameters for XGBoost: {best_params}\")\n",
    "\n",
    "xgBoost_model.fit(X_train, y_train)\n",
    "y_pred_xgBoost = xgBoost_model.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-21T12:15:59.964920Z",
     "end_time": "2023-05-21T12:16:03.535195Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Baseline Model - Naive Bayes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "outputs": [],
   "source": [
    "nBay_model = GaussianNB()\n",
    "nBay_model.fit(X_train, y_train)\n",
    "y_pred_nBay = nBay_model.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-21T12:16:03.536196Z",
     "end_time": "2023-05-21T12:16:03.570249Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Baseline Model - SVC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "outputs": [],
   "source": [
    "svc_model = SVC(kernel='rbf', C=1, gamma='auto')\n",
    "svc_model.fit(X_train, y_train)\n",
    "y_pred_svc = svc_model.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-21T12:16:03.570249Z",
     "end_time": "2023-05-21T12:16:24.215468Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Baseline Model - kNeighbors Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred_knn = knn_model.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-21T12:16:24.220470Z",
     "end_time": "2023-05-21T12:16:24.833511Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.8018220227092685\n",
      "Decision Tree Accuracy: 0.8040665434380776\n",
      "Random Forest Accuracy: 0.7993134407182466\n",
      "XGBoost Accuracy: 0.8023501452336942\n",
      "Naive Bayes Accuracy: 0.7896752046474782\n",
      "SVC Accuracy: 0.8047266965936097\n",
      "kNeighbors Classifier Accuracy: 0.7391074729337206\n"
     ]
    }
   ],
   "source": [
    "# --- Calculate the accuracy of the Logistic Regression model\n",
    "accuracy_logReg = accuracy_score(y_test, y_pred_logReg)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_logReg)\n",
    "# 81%\n",
    "# 81% (Entfernung collreationsspalten wg. OneHot & max_iter definiert)\n",
    "# 57% (Balancing)\n",
    "# 57% (Balancing and Normalized)\n",
    "# 81% (No Balancing and Normalized)\n",
    "# 79% (StandardScaler instead of MinMaxScaler and removed duplicates from raw dataset)\n",
    "# 79% (Feature Selection and MinMaxScaler)\n",
    "# 80% (Only First Tries and ['hour', 'amount', '3D_secured', 'is_weekend', 'Goldcard', 'Simplecard', 'UK_Card'])\n",
    "\n",
    "# --- Calculate the accuracy of the Decision Tree model\n",
    "accuracy_decTree = accuracy_score(y_test, y_pred_decTree)\n",
    "print(\"Decision Tree Accuracy:\", accuracy_decTree)\n",
    "# 71%\n",
    "# 75% (Entfernung collreationsspalten wg. OneHot)\n",
    "# 57% (Balancing)\n",
    "# 57% (Balancing and Normalized)\n",
    "# 75% (No Balancing and Normalized)\n",
    "# 73% (StandardScaler instead of MinMaxScaler and removed duplicates from raw dataset)\n",
    "# 79% (Feature Selection and MinMaxScaler)\n",
    "# 80% (Only First Tries and ['hour', 'amount', '3D_secured', 'is_weekend', 'Goldcard', 'Simplecard', 'UK_Card'])\n",
    "\n",
    "\n",
    "# --- Calculate the accuracy of the Random Forest model\n",
    "accuracy_ranForest = accuracy_score(y_test, y_pred_ranForest)\n",
    "print(\"Random Forest Accuracy:\", accuracy_ranForest)\n",
    "# 77%\n",
    "# 75% (Entfernung collreationsspalten wg. OneHot)\n",
    "# 57% (Balancing)\n",
    "# 57% (Balancing and Normalized)\n",
    "# 75% (No Balancing and Normalized)\n",
    "# 73% (StandardScaler instead of MinMaxScaler and removed duplicates from raw dataset)\n",
    "# 79% (Feature Selection and MinMaxScaler)\n",
    "# 80% (Only First Tries and ['hour', 'amount', '3D_secured', 'is_weekend', 'Goldcard', 'Simplecard', 'UK_Card'])\n",
    "\n",
    "# --- Calculate the accuracy of the XGBoost model\n",
    "accuracy_xgBoost = accuracy_score(y_test, y_pred_xgBoost)\n",
    "print(\"XGBoost Accuracy:\", accuracy_xgBoost)\n",
    "# 81% (No Balancing and Normalized)\n",
    "# 79% (StandardScaler instead of MinMaxScaler and removed duplicates from raw dataset)\n",
    "# 79% (Feature Selection and MinMaxScaler)\n",
    "# 80% (Only First Tries and ['hour', 'amount', '3D_secured', 'is_weekend', 'Goldcard', 'Simplecard', 'UK_Card'])\n",
    "\n",
    "# --- Calculate the accuracy of the Naive Bayes model\n",
    "accuracy_nBay = accuracy_score(y_test, y_pred_nBay)\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_nBay)\n",
    "# 81% (No Balancing and Normalized)\n",
    "# 79% (StandardScaler instead of MinMaxScaler and removed duplicates from raw dataset)\n",
    "# 78% (Feature Selection and MinMaxScaler)\n",
    "# 79% (Only First Tries and ['hour', 'amount', '3D_secured', 'is_weekend', 'Goldcard', 'Simplecard', 'UK_Card'])\n",
    "\n",
    "\n",
    "# --- Calculate the accuracy of the SVC model\n",
    "accuracy_svc = accuracy_score(y_test, y_pred_svc)\n",
    "print(\"SVC Accuracy:\", accuracy_svc)\n",
    "# 81% (No Balancing and Normalized)\n",
    "# 79% (StandardScaler instead of MinMaxScaler and removed duplicates from raw dataset)\n",
    "# 79% (Feature Selection and MinMaxScaler)\n",
    "# 80% (Only First Tries and ['hour', 'amount', '3D_secured', 'is_weekend', 'Goldcard', 'Simplecard', 'UK_Card'])\n",
    "\n",
    "# --- Calculate the accuracy of the kNeighbors Classifier model\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(\"kNeighbors Classifier Accuracy:\", accuracy_knn)\n",
    "# 76% (No Balancing and Normalized)\n",
    "# 74% (StandardScaler instead of MinMaxScaler and removed duplicates from raw dataset)\n",
    "# 79% (Feature Selection and MinMaxScaler)\n",
    "# 74% (Only First Tries and ['hour', 'amount', '3D_secured', 'is_weekend', 'Goldcard', 'Simplecard', 'UK_Card'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-21T12:16:24.841511Z",
     "end_time": "2023-05-21T12:16:24.893514Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
